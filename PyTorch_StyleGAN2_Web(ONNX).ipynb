{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch_StyleGAN2_Web(ONNX).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFjVwUap4Q0I",
        "outputId": "f036dcb2-1e1f-4afa-c598-4bb06adad7ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "32JtLa3wJGNY",
        "outputId": "7dae6736-826a-4d35-bcb5-35e596c2a42c"
      },
      "source": [
        "'''%データセットのダウンロード\n",
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "file_id = \"1-EyM2kIj24P6DtT-swZP8DLyBAPU1PkU\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output = \"dataset.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip \"dataset.zip\"\n",
        "'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'%データセットのダウンロード\\n!pip install gdown\\n\\nimport gdown\\nfile_id = \"1-EyM2kIj24P6DtT-swZP8DLyBAPU1PkU\"\\nurl = f\"https://drive.google.com/uc?id={file_id}\"\\noutput = \"dataset.zip\"\\ngdown.download(url, output, quiet=False)\\n!unzip \"dataset.zip\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o_3yBZqJwOc",
        "outputId": "ce70aea2-ded7-4ff5-ad96-a66dbffb3276"
      },
      "source": [
        "#import libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "print(torch.__version__)\n",
        "torch.manual_seed(0)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f793a10ead0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "hyBEqiIn3nqI",
        "outputId": "8dd0c3c8-962a-446e-fbbf-3518ec8c5474"
      },
      "source": [
        "image = torch.rand(1,3,4,4)\n",
        "\n",
        "image_2 = nn.Upsample(scale_factor=2, mode='nearest')(image)\n",
        "\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "print(image_2.reshape(1,3,1,-1))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-af670e3795df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO_Cl9QBJyU0",
        "outputId": "6c3181bf-b3ab-4aea-fa54-db9da795d200"
      },
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "LReLU_alpha = 0.2\n",
        "mapping_lamda = 0.01\n",
        "\n",
        "#https://github.com/yuuho/stylegans-pytorch/blob/master/network/stylegan2.py　を参考に\n",
        "from torch.nn import functional as F\n",
        "class modulated_conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
        "        super(modulated_conv2d, self).__init__()\n",
        "        self.padding, self.stride = padding, stride\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        torch.nn.init.normal_(self.weight.data, mean=0.0, std=1.0)\n",
        "        self.bias = nn.Parameter(torch.zeros(1,out_channels,1,1))\n",
        "        self.weight_scaler = 1 / (in_channels * kernel_size*kernel_size)**0.5\n",
        "        \n",
        "    def forward(self,x,style,shape = None):\n",
        "        oC,iC,kH,kW = self.weight.shape\n",
        "        if shape is None:\n",
        "            N, iC, H, W = x.shape\n",
        "        else:\n",
        "            N, iC, H, W = shape\n",
        "        modulated_weight = self.weight_scaler*self.weight.view(1,iC,oC,kH,kW) \\\n",
        "                                * style.view(N,iC,1,1,1) # (N,iC,oC,kH,kW)\n",
        "        demod_norm = 1 / torch.sqrt((modulated_weight * modulated_weight).sum([1,3,4]) + 1e-8) # (N, oC)\n",
        "        demodulated_weight = modulated_weight * demod_norm.view(N, 1, oC, 1, 1) # (N,iC,oC,kH,kW)\n",
        "        out = F.conv2d(x.view(1,N*iC,H,W), demodulated_weight.view(N*oC,iC,kH,kW),\n",
        "                padding=self.padding, stride=self.stride, groups=N).view(N,oC,H,W) + self.bias\n",
        "        return out\n",
        "\n",
        "def alternative_Upsample(image,input_size):\n",
        "    #image_shape = list(image.shape)\n",
        "    #image_shape = [int(item) for item in image_shape]\n",
        "    #x = torch.reshape(image, (batches, channels, h * w, 1))\n",
        "    batches, channels, h, w = input_size\n",
        "    x = image.view(batches, channels, h * w, 1)\n",
        "    x = torch.cat((x,x),3)\n",
        "    #x = torch.reshape(x, (batches, channels, h, w * 2))\n",
        "    x = x.view(batches, channels, h, w * 2)\n",
        "    x = torch.cat((x,x),3)\n",
        "    #x = torch.reshape(x, (batches, channels, h * 2, w * 2))\n",
        "    x = x.view(batches, channels, h * 2, w * 2)\n",
        "    return x\n",
        "# Define model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        dimensions = [256,256,256,256,128,128,128,64,64,64,32,32]\n",
        "        self.learning_const = torch.randn((1,dimensions[1],4,4),requires_grad=True, device = device)\n",
        "        self.mapping_network = self.generate_mapping_network(dimensions[0])\n",
        "\n",
        "        self.affine_4_0 = self.make_latent_to_style(dimensions[0],dimensions[1])\n",
        "        self.block_4_0 = self.generate_block(4,dimensions[1],dimensions[2])\n",
        "        self.noise_4_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_4_1 = self.make_latent_to_style(dimensions[0],dimensions[2])\n",
        "        self.block_4_1 = self.generate_block(4,dimensions[2],dimensions[3])\n",
        "        self.noise_4_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_4 = nn.Conv2d(dimensions[3],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_8_0 = self.make_latent_to_style(dimensions[0],dimensions[3])\n",
        "        self.block_8_0 = self.generate_block(8,dimensions[3],dimensions[4],True)\n",
        "        self.noise_8_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_8_1 = self.make_latent_to_style(dimensions[0],dimensions[4])\n",
        "        self.block_8_1 = self.generate_block(8,dimensions[4],dimensions[5])\n",
        "        self.noise_8_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_8 = nn.Conv2d(dimensions[5],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_16_0 = self.make_latent_to_style(dimensions[0],dimensions[5])\n",
        "        self.block_16_0 = self.generate_block(16,dimensions[5],dimensions[6],True)\n",
        "        self.noise_16_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_16_1 = self.make_latent_to_style(dimensions[0],dimensions[6])\n",
        "        self.block_16_1 = self.generate_block(16,dimensions[6],dimensions[7])\n",
        "        self.noise_16_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_16 = nn.Conv2d(dimensions[7],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_32_0 = self.make_latent_to_style(dimensions[0],dimensions[7])\n",
        "        self.block_32_0 = self.generate_block(32,dimensions[7],dimensions[8],True)\n",
        "        self.noise_32_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_32_1 = self.make_latent_to_style(dimensions[0],dimensions[8])\n",
        "        self.block_32_1 = self.generate_block(32,dimensions[8],dimensions[9])\n",
        "        self.noise_32_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_32 = nn.Conv2d(dimensions[9],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_64_0 = self.make_latent_to_style(dimensions[0],dimensions[9])\n",
        "        self.block_64_0 = self.generate_block(64,dimensions[9],dimensions[10],True)\n",
        "        self.noise_64_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_64_1 = self.make_latent_to_style(dimensions[0],dimensions[10])\n",
        "        self.block_64_1 = self.generate_block(64,dimensions[10],dimensions[11])\n",
        "        self.noise_64_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_64 = nn.Conv2d(dimensions[11],3,kernel_size=1,stride=1,padding=0)\n",
        "        for i in range(5):\n",
        "            nn.init.normal_(getattr(self, 'to_rgb_{0}'.format(2 ** (i + 2))).weight, 0.0, 1.0 / getattr(self, 'to_rgb_{0}'.format(2 ** (i + 2))).weight.shape[1] ** 0.5)\n",
        "            nn.init.constant_(getattr(self, 'to_rgb_{0}'.format(2 ** (i + 2))).bias, 0.0)\n",
        "            \n",
        "            for j in range(2):\n",
        "                nn.init.normal_(getattr(self, 'affine_{0}_{1}'.format(2 ** (i + 2),j)).weight, 0.0, 1.0)\n",
        "                nn.init.constant_(getattr(self, 'affine_{0}_{1}'.format(2 ** (i + 2),j)).bias, 1.0)         \n",
        "\n",
        "    def generate_mapping_network(self,dimension = 512,number_of_layer = 1):\n",
        "       mapping_network = nn.Sequential()\n",
        "       for i in range(number_of_layer):\n",
        "           mapping_network.add_module('mapping_fc{0}'.format(i), nn.Linear(dimension,dimension))\n",
        "           mapping_network.add_module('mapping_lrelu{0}'.format(i), nn.LeakyReLU())\n",
        "           nn.init.normal_(getattr(mapping_network, 'mapping_fc{0}'.format(i)).weight, 0.0, 1.0)\n",
        "           nn.init.constant_(getattr(mapping_network, 'mapping_fc{0}'.format(i)).bias, 0)\n",
        "       return mapping_network\n",
        "\n",
        "    def generate_block(self,image_size = 4,in_dimension = 512, out_dimension = 512,upscaling = False):\n",
        "        return modulated_conv2d(in_dimension,out_dimension,kernel_size=3,stride=1,padding=1)\n",
        "        #return torch.nn.Conv2d(in_dimension,out_dimension,kernel_size=3,stride=1,padding=1)\n",
        "    def make_latent_to_style(self,latent_dimension = 512, target_dimension = 512):\n",
        "\n",
        "        return nn.Linear(latent_dimension, target_dimension)\n",
        "    def forward(self, z, stage = 1 ,alpha = 0, batches = 1,web = False):\n",
        "        style = self.mapping_network(z) * mapping_lamda\n",
        "        x = self.learning_const.repeat(int(batches),1,1,1)\n",
        "        for i in range(stage):\n",
        "            if i != 0:\n",
        "                if web:\n",
        "                    x = alternative_Upsample(x,(1,-1,2 ** (i + 1),2 ** (i + 1)))\n",
        "                else:\n",
        "                    x = torch.nn.functional.interpolate(x,scale_factor=2, mode='nearest')\n",
        "            for j in range(2):\n",
        "                if not (i == 0 and j == 0):\n",
        "                    affined_style = getattr(self, 'affine_{0}_{1}'.format(2 ** (i + 2),j))(style)\n",
        "                    x = getattr(self, 'block_{0}_{1}'.format(2 ** (i + 2),j))(x,affined_style,shape = (1,-1,2 ** (i + 2),2 ** (i + 2)))\n",
        "                    x = F.leaky_relu(x,LReLU_alpha)\n",
        "                    #x = x + torch.randn(x.shape, device = device) *  getattr(self, 'noise_{0}_{1}'.format(2 ** (i + 2),j))\n",
        "\n",
        "        x_out = getattr(self, 'to_rgb_{0}'.format(2 ** (stage + 1)))(x)\n",
        "\n",
        "        if alpha != 0:\n",
        "            if web:\n",
        "                x = alternative_Upsample(x,(1,-1,2 ** (stage + 1),2 ** (stage + 1)))\n",
        "            else:\n",
        "                x = torch.nn.functional.interpolate(x,scale_factor=2, mode='nearest')\n",
        "            for j in range(2):\n",
        "                affined_style = getattr(self, 'affine_{0}_{1}'.format(2 ** (stage + 2),j))(style)\n",
        "                x = getattr(self, 'block_{0}_{1}'.format(2 ** (stage + 2),j))(x,affined_style,shape = (1,-1,2 ** (stage + 1),2 ** (stage + 1)))\n",
        "                x = F.leaky_relu(x,LReLU_alpha)\n",
        "                #x = x + torch.randn(x.shape, device = device) * getattr(self, 'noise_{0}_{1}'.format(2 ** (i + 2),j))\n",
        "            x = getattr(self, 'to_rgb_{0}'.format(2 ** (stage + 2)))(x)\n",
        "            if web:\n",
        "                x_out = alpha * x + alternative_Upsample(x_out,(1,-1,2 ** (stage + 1),2 ** (stage + 1))) * (1 - alpha)\n",
        "            else:\n",
        "                x_out = alpha * x + torch.nn.functional.interpolate(x,scale_factor=2, mode='nearest') * (1 - alpha)\n",
        "            \n",
        "        return x_out"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl4fVrUadKk4"
      },
      "source": [
        "# Define model\n",
        "from torch.autograd import Variable\n",
        "from torch import autograd\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        dimensions = [256,256,256,128,128,128,64,64,64,32,32,32]\n",
        "\n",
        "        self.from_rgb_4 = nn.Conv2d(3,dimensions[2],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_4_0 = self.generate_block(4,dimensions[2],dimensions[1])\n",
        "        self.block_4_1 = self.generate_block(4,dimensions[1],dimensions[0])\n",
        "\n",
        "        self.from_rgb_8 = nn.Conv2d(3,dimensions[4],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_8_0 = self.generate_block(8,dimensions[4],dimensions[3])\n",
        "        self.block_8_1 = self.generate_block(8,dimensions[3],dimensions[2])\n",
        "\n",
        "        self.from_rgb_16 = nn.Conv2d(3,dimensions[6],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_16_0 = self.generate_block(16,dimensions[6],dimensions[5])\n",
        "        self.block_16_1 = self.generate_block(16,dimensions[5],dimensions[4])\n",
        "\n",
        "        self.from_rgb_32 = nn.Conv2d(3,dimensions[8],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_32_0 = self.generate_block(32,dimensions[8],dimensions[7])\n",
        "        self.block_32_1 = self.generate_block(32,dimensions[7],dimensions[6])\n",
        "\n",
        "        self.from_rgb_64 = nn.Conv2d(3,dimensions[10],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_64_0 = self.generate_block(64,dimensions[10],dimensions[9])\n",
        "        self.block_64_1 = self.generate_block(64,dimensions[9],dimensions[8])\n",
        "\n",
        "        self.final_conv = nn.Conv2d(dimensions[0],dimensions[0],kernel_size=4,stride=1,padding=0)\n",
        "        self.linear = nn.Linear(dimensions[0],1)\n",
        "        nn.init.normal_(self.final_conv.weight, 0.0, 1.0 / (4*4**dimensions[0]) ** 0.5)\n",
        "        nn.init.constant_(self.final_conv.bias, 0)\n",
        "        nn.init.normal_(self.linear.weight, 0.0, 1.0)\n",
        "        nn.init.constant_(self.linear.bias, 0)\n",
        "        for i in range(5):\n",
        "            nn.init.normal_(getattr(self, 'from_rgb_{0}'.format(2 ** (i + 2))).weight, 0.0, 1.0 / getattr(self, 'from_rgb_{0}'.format(2 ** (i + 2))).weight.shape[1] ** 0.5)\n",
        "            nn.init.constant_(getattr(self, 'from_rgb_{0}'.format(2 ** (i + 2))).bias, 0.0)\n",
        "\n",
        "    def generate_block(self,image_size = 4,in_dimension = 512, out_dimension = 512):\n",
        "        block = nn.Sequential()\n",
        "\n",
        "        block.add_module('Conv', nn.Conv2d(in_dimension,out_dimension,kernel_size=3,stride=1,padding=1))\n",
        "        block.add_module('relu', nn.LeakyReLU(LReLU_alpha))\n",
        "        nn.init.normal_(block.Conv.weight, 0.0, 1.0)\n",
        "        nn.init.constant_(block.Conv.bias, 0)\n",
        "\n",
        "        return block\n",
        "    #https://github.com/Zeleni9/pytorch-wgan/blob/master/models/wgan_gradient_penalty.py を改変\n",
        "    def calculate_gradient_penalty(self, real_images, fake_images,batch_size,stage,alpha):\n",
        "        eta = torch.FloatTensor(batch_size,1,1,1).uniform_(0,1).to(device)\n",
        "        eta = eta.expand(batch_size, real_images.size(1), real_images.size(2), real_images.size(3))\n",
        "\n",
        "        interpolated = eta * real_images + ((1 - eta) * fake_images)\n",
        "\n",
        "        # define it to calculate gradient\n",
        "        interpolated = Variable(interpolated, requires_grad=True)\n",
        "        # calculate probability of interpolated examples\n",
        "        prob_interpolated = self(interpolated,stage,alpha)\n",
        "        # calculate gradients of probabilities with respect to examples\n",
        "        gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                              grad_outputs=torch.ones(\n",
        "                                  prob_interpolated.size()).to(device),\n",
        "                              create_graph=True, retain_graph=True)[0]\n",
        "        grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "        return grad_penalty\n",
        "    \n",
        "    def forward(self, image, stage = 1 ,alpha = 0, batches = 1):\n",
        "        if alpha != 0:\n",
        "            x = getattr(self, 'from_rgb_{0}'.format(2 ** (stage + 2)))(image)\n",
        "            for j in range(2):\n",
        "                x = getattr(self, 'block_{0}_{1}'.format(2 ** (stage + 2),j))(x)\n",
        "            x = torch.nn.functional.interpolate(x,scale_factor=0.5, mode='nearest')\n",
        "            x2 = getattr(self, 'from_rgb_{0}'.format(2 ** (stage + 1)))(torch.nn.functional.interpolate(image,scale_factor=0.5, mode='nearest'))\n",
        "            x = x * alpha + x2 * (1 - alpha)\n",
        "        else:\n",
        "            x = getattr(self, 'from_rgb_{0}'.format(2 ** (stage + 1)))(image)\n",
        "\n",
        "        for i in range(stage):\n",
        "            for j in range(2):\n",
        "                if not (i == stage - 1 and j == 1):\n",
        "                    x = getattr(self, 'block_{0}_{1}'.format(2 ** (stage + 1 - i),j))(x)\n",
        "            if i != stage - 1:\n",
        "                x = torch.nn.functional.interpolate(x,scale_factor=0.5, mode='nearest')\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "        \n",
        "        x = nn.LeakyReLU(LReLU_alpha)(x)\n",
        "        x = nn.Flatten()(x)\n",
        "        return  self.linear(x)"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evars0QQOPuM"
      },
      "source": [
        "class trainer():\n",
        "    def __init__(self,learning_rate = 0.0002):\n",
        "        self.alpha = 0\n",
        "        self.stage = 0\n",
        "        self.MAX_STAGE = 4\n",
        "        self.BATCH_SIZE = 32\n",
        "        self.n_critic = 1\n",
        "        self.gp_lamda = 1\n",
        "        self.g = Generator().to(device)\n",
        "        self.d = Discriminator().to(device)\n",
        "        self.G_optimizer = torch.optim.Adam(self.g.parameters(), lr=learning_rate)\n",
        "        self.D_optimizer = torch.optim.Adam(self.d.parameters(), lr=learning_rate)\n",
        "        self.NUM_EPOCH_NO_ALPHA = 50\n",
        "        self.NUM_EPOCH_WITH_ALPHA = 50\n",
        "        self.z_dimension = 256\n",
        "    def train(self):\n",
        "        MAX_STAGE = self.MAX_STAGE\n",
        "        BATCH_SIZE = self.BATCH_SIZE\n",
        "        n_critic = self.n_critic\n",
        "        gp_lamda = self.gp_lamda\n",
        "        g = self.g\n",
        "        d = self.d\n",
        "        G_optimizer = self.G_optimizer\n",
        "        D_optimizer = self.D_optimizer\n",
        "        NUM_EPOCH_NO_ALPHA = self.NUM_EPOCH_NO_ALPHA\n",
        "        NUM_EPOCH_WITH_ALPHA = self.NUM_EPOCH_WITH_ALPHA\n",
        "        z_dimension = self.z_dimension\n",
        "        training_data = datasets.CIFAR10(\n",
        "            root=\"data\",\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=ToTensor(),\n",
        "        )\n",
        "        train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "        while True:\n",
        "            for epoch in range(NUM_EPOCH_NO_ALPHA + NUM_EPOCH_WITH_ALPHA):\n",
        "                number_of_batch = 0\n",
        "                for X, _ in train_dataloader:\n",
        "                    X = X * 2 - 1\n",
        "                    \n",
        "                    alpha = 0\n",
        "                    if int(self.stage) % 2 == 1:\n",
        "                        self.stage += 1 / (len(train_dataloader) * NUM_EPOCH_WITH_ALPHA) \n",
        "                    elif math.ceil(self.stage / 2) < self.MAX_STAGE:\n",
        "                        self.stage += 1 / (len(train_dataloader) * NUM_EPOCH_NO_ALPHA)\n",
        "                    stage = math.ceil(self.stage / 2)    \n",
        "                    if int(self.stage) % 2 == 1:\n",
        "                        alpha = self.stage - int(self.stage)\n",
        "                    \n",
        "                    for _ in range(n_critic):\n",
        "                        z = torch.randn((BATCH_SIZE,z_dimension),device = device)\n",
        "                        generated = g(z, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        X = X.to(device)\n",
        "                        X = torch.nn.functional.interpolate(X,size=generated.size(2), mode='Nearest')\n",
        "                        y_real = d(X, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        y_fake = d(generated, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        d_loss = torch.mean(y_fake) - torch.mean(y_real) + d.calculate_gradient_penalty(X,generated,BATCH_SIZE,stage,alpha) * gp_lamda\n",
        "                        Wasserstein_loss =  (torch.mean(y_fake) - torch.mean(y_real)).data\n",
        "\n",
        "                        D_optimizer.zero_grad()\n",
        "                        d_loss.backward()\n",
        "                        D_optimizer.step()\n",
        "                    g_loss = 'undefined'\n",
        "                    if Wasserstein_loss <= 0:\n",
        "                        z = torch.randn((BATCH_SIZE,z_dimension),device = device)\n",
        "                        generated = g(z, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        y_fake = d(generated, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        g_loss = -torch.mean(y_fake)\n",
        "                        G_optimizer.zero_grad()\n",
        "                        g_loss.backward()\n",
        "                        G_optimizer.step()\n",
        "\n",
        "                    \n",
        "\n",
        "                    if number_of_batch % 100 == 0:\n",
        "                        print('epoch:{}, batch:{},stage:{},alpha{},g_loss:{}, d_loss:{}, Wasserstein Loss:{}'.format(epoch,number_of_batch,stage,alpha,g_loss,d_loss,Wasserstein_loss))\n",
        "                        show_image(generated)\n",
        "                        show_image(X)\n",
        "                        torch.save(self, '/content/drive/MyDrive/StyleGAN2/model.pth')\n",
        "                    number_of_batch += 1"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMy29H2BzU5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311377b1-518a-4567-cc9f-0c684c4c5693"
      },
      "source": [
        "try:\n",
        "    train = torch.load('/content/drive/MyDrive/StyleGAN2/model.pth')\n",
        "except:\n",
        "    train = trainer()\n",
        "    print('load failed')\n",
        "\n",
        "dummy_input = torch.randn(1, train.z_dimension, device=device)\n",
        "train.g.learning_const.requires_grad = False\n",
        "for i in range(5):  \n",
        "    for j in range(2):\n",
        "        getattr(train.g, 'noise_{0}_{1}'.format(2 ** (i + 2),j)).requires_grad = False\n",
        "        getattr(train.g, 'noise_{0}_{1}'.format(2 ** (i + 2),j)).requires_grad = False\n",
        "stage = torch.tensor(2, dtype=torch.int)\n",
        "alpha = torch.tensor(0, dtype=torch.int)\n",
        "batches = torch.tensor(1, dtype=torch.int)\n",
        "web = torch.tensor(True, dtype=torch.bool)\n",
        "torch.onnx.export(train.g, (dummy_input,stage,alpha,batches,web), 'generator.onnx')"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:117: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:120: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:133: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DBqbMLLl5Ip8",
        "outputId": "c78b242a-81df-4ef4-8702-b5f73d7dff54"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('generator.onnx')"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e2f08b29-6aa1-4d5d-ae27-53c05a33fc19\", \"generator.onnx\", 6919324)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U3QtR8bhtjQ",
        "outputId": "4b9dd4f2-9c1a-4d07-af75-65ca74c5f222"
      },
      "source": [
        "z = torch.zeros((1,256),device = device)\n",
        "print(torch.std(train.g(z)))\n",
        "print(train.g(z).shape)\n",
        "\n",
        "print(train.stage)"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.0216, device='cuda:0', grad_fn=<StdBackward0>)\n",
            "torch.Size([1, 3, 4, 4])\n",
            "2.8648527528893295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVwX2F02PalU",
        "outputId": "df72d48b-4fb7-4148-b82a-a04e563e9f30"
      },
      "source": [
        "pip install onnx"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx) (56.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}