{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch_StyleGAN2_Web(ONNX).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFjVwUap4Q0I",
        "outputId": "04990194-4a14-4471-df7d-0393cc35573f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "32JtLa3wJGNY",
        "outputId": "a11d7a55-ea5d-411d-8219-52a659614a02"
      },
      "source": [
        "'''%データセットのダウンロード\n",
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "file_id = \"1-EyM2kIj24P6DtT-swZP8DLyBAPU1PkU\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output = \"dataset.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip \"dataset.zip\"\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'%データセットのダウンロード\\n!pip install gdown\\n\\nimport gdown\\nfile_id = \"1-EyM2kIj24P6DtT-swZP8DLyBAPU1PkU\"\\nurl = f\"https://drive.google.com/uc?id={file_id}\"\\noutput = \"dataset.zip\"\\ngdown.download(url, output, quiet=False)\\n!unzip \"dataset.zip\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o_3yBZqJwOc",
        "outputId": "fa28442c-85a2-45bf-f3a1-46d85c8a536c"
      },
      "source": [
        "#import libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "print(torch.__version__)\n",
        "torch.manual_seed(0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7b0965bb30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO_Cl9QBJyU0",
        "outputId": "791ee9dc-75e6-4e34-b7f9-67f30aacfb57"
      },
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "LReLU_alpha = 0.2\n",
        "mapping_lamda = 0.01\n",
        "\n",
        "#https://github.com/yuuho/stylegans-pytorch/blob/master/network/stylegan2.py　を参考に\n",
        "from torch.nn import functional as F\n",
        "class modulated_conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
        "        super(modulated_conv2d, self).__init__()\n",
        "        self.padding, self.stride = padding, stride\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        torch.nn.init.normal_(self.weight.data, mean=0.0, std=1.0)\n",
        "        #self.weight = nn.Parameter(torch.zeros(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(1,out_channels,1,1))\n",
        "        self.weight_scaler = 1 / (in_channels * kernel_size*kernel_size)**0.5\n",
        "\n",
        "    def forward(self,x,style,shape = None,web = True,style_2 = None):\n",
        "        oC, iC, kH, kW = self.weight.shape\n",
        "        if shape is None:\n",
        "            N, iC, H, W = x.shape\n",
        "        else:\n",
        "            N, iC, H, W = shape\n",
        "\n",
        "        if web:\n",
        "            modulated_weight = self.weight.view(1,oC,iC,kH,kW) * self.weight_scaler \n",
        "            #modulated_weight = modulated_weight.repeat(N,1,1,1,1)\n",
        "            x = x * style.view(N,iC,1,1)\n",
        "            x = F.conv2d(x.view(1,N*iC,H,W), modulated_weight.view(N*oC,iC,kH,kW),\n",
        "                    padding=self.padding, stride=self.stride, groups=N).view(N,oC,H,W)\n",
        "            modulated_weight = modulated_weight * style_2.view(N,1,iC,1,1)\n",
        "            demod_norm = 1 / torch.sqrt((modulated_weight * modulated_weight).sum([2,3,4])  + 1e-8)\n",
        "            out = x * demod_norm.view(N, oC, 1, 1) + self.bias   \n",
        "\n",
        "        else:\n",
        "            modulated_weight = self.weight_scaler*self.weight.view(1,oC,iC,kH,kW) \\\n",
        "                                    * style.view(N,1,iC,1,1) \n",
        "\n",
        "            demod_norm = 1 / torch.sqrt((modulated_weight * modulated_weight).sum([2,3,4]) + 1e-8) # (N, oC)\n",
        "            demodulated_weight = modulated_weight * demod_norm.view(N, oC, 1, 1, 1) \n",
        "            #demodulated_weight = modulated_weight\n",
        "            out = F.conv2d(x.view(1,N*iC,H,W), demodulated_weight.view(N*oC,iC,kH,kW),\n",
        "                    padding=self.padding, stride=self.stride, groups=N).view(N,oC,H,W) + self.bias\n",
        "            \n",
        "        return out\n",
        "\n",
        "def alternative_Upsample(image,input_size):\n",
        "    batches, channels, h, w = input_size\n",
        "\n",
        "    x = image.view(batches, channels, h * w, 1)\n",
        "    x = torch.cat((x,x),3)\n",
        "    x = x.view(batches, channels, h, w * 2)\n",
        "    x = torch.cat((x,x),3)\n",
        "    x = x.view(batches, channels, h * 2, w * 2)\n",
        "    return x\n",
        "# Define model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        dimensions = [256,256,256,256,128,128,128,64,64,64,32,32]\n",
        "        self.learning_const = torch.randn((1,dimensions[1],4,4),requires_grad=True, device = device)\n",
        "        self.mapping_network = self.generate_mapping_network(dimensions[0])\n",
        "\n",
        "        self.affine_4_0 = self.make_latent_to_style(dimensions[0],dimensions[1])\n",
        "        self.block_4_0 = self.generate_block(4,dimensions[1],dimensions[2])\n",
        "        self.noise_4_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_4_1 = self.make_latent_to_style(dimensions[0],dimensions[2])\n",
        "        self.block_4_1 = self.generate_block(4,dimensions[2],dimensions[3])\n",
        "        self.noise_4_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_4 = nn.Conv2d(dimensions[3],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_8_0 = self.make_latent_to_style(dimensions[0],dimensions[3])\n",
        "        self.block_8_0 = self.generate_block(8,dimensions[3],dimensions[4],True)\n",
        "        self.noise_8_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_8_1 = self.make_latent_to_style(dimensions[0],dimensions[4])\n",
        "        self.block_8_1 = self.generate_block(8,dimensions[4],dimensions[5])\n",
        "        self.noise_8_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_8 = nn.Conv2d(dimensions[5],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_16_0 = self.make_latent_to_style(dimensions[0],dimensions[5])\n",
        "        self.block_16_0 = self.generate_block(16,dimensions[5],dimensions[6],True)\n",
        "        self.noise_16_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_16_1 = self.make_latent_to_style(dimensions[0],dimensions[6])\n",
        "        self.block_16_1 = self.generate_block(16,dimensions[6],dimensions[7])\n",
        "        self.noise_16_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_16 = nn.Conv2d(dimensions[7],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_32_0 = self.make_latent_to_style(dimensions[0],dimensions[7])\n",
        "        self.block_32_0 = self.generate_block(32,dimensions[7],dimensions[8],True)\n",
        "        self.noise_32_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_32_1 = self.make_latent_to_style(dimensions[0],dimensions[8])\n",
        "        self.block_32_1 = self.generate_block(32,dimensions[8],dimensions[9])\n",
        "        self.noise_32_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_32 = nn.Conv2d(dimensions[9],3,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        self.affine_64_0 = self.make_latent_to_style(dimensions[0],dimensions[9])\n",
        "        self.block_64_0 = self.generate_block(64,dimensions[9],dimensions[10],True)\n",
        "        self.noise_64_0 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.affine_64_1 = self.make_latent_to_style(dimensions[0],dimensions[10])\n",
        "        self.block_64_1 = self.generate_block(64,dimensions[10],dimensions[11])\n",
        "        self.noise_64_1 = torch.zeros((1,),requires_grad=True, device = device)\n",
        "        self.to_rgb_64 = nn.Conv2d(dimensions[11],3,kernel_size=1,stride=1,padding=0)\n",
        "        for i in range(5):\n",
        "            nn.init.normal_(getattr(self, 'to_rgb_{0}'.format(2 ** (i + 2))).weight, 0.0, 1.0 / getattr(self, 'to_rgb_{0}'.format(2 ** (i + 2))).weight.shape[1] ** 0.5)\n",
        "            nn.init.constant_(getattr(self, 'to_rgb_{0}'.format(2 ** (i + 2))).bias, 0.0)\n",
        "            \n",
        "            for j in range(2):\n",
        "                nn.init.normal_(getattr(self, 'affine_{0}_{1}'.format(2 ** (i + 2),j)).weight, 0.0, 1.0)\n",
        "                nn.init.constant_(getattr(self, 'affine_{0}_{1}'.format(2 ** (i + 2),j)).bias, 1.0)         \n",
        "\n",
        "    def generate_mapping_network(self,dimension = 512,number_of_layer = 1):\n",
        "       mapping_network = nn.Sequential()\n",
        "       for i in range(number_of_layer):\n",
        "           mapping_network.add_module('mapping_fc{0}'.format(i), nn.Linear(dimension,dimension))\n",
        "           mapping_network.add_module('mapping_lrelu{0}'.format(i), nn.LeakyReLU())\n",
        "           nn.init.normal_(getattr(mapping_network, 'mapping_fc{0}'.format(i)).weight, 0.0, 1.0)\n",
        "           nn.init.constant_(getattr(mapping_network, 'mapping_fc{0}'.format(i)).bias, 0)\n",
        "       return mapping_network\n",
        "\n",
        "    def generate_block(self,image_size = 4,in_dimension = 512, out_dimension = 512,upscaling = False):\n",
        "        return modulated_conv2d(in_dimension,out_dimension,kernel_size=3,stride=1,padding=1)\n",
        "        #return torch.nn.Conv2d(in_dimension,out_dimension,kernel_size=3,stride=1,padding=1)\n",
        "    def make_latent_to_style(self,latent_dimension = 512, target_dimension = 512):\n",
        "\n",
        "        return nn.Linear(latent_dimension, target_dimension)\n",
        "    def forward(self, z, stage = 1 ,alpha = 0, batches = 1,web = False):\n",
        "        style = self.mapping_network(z) * mapping_lamda\n",
        "        if web:\n",
        "            #mapping_network_2 = self.mapping_network_2(z)\n",
        "            style_2 = self.mapping_network(z) * mapping_lamda\n",
        "\n",
        "        x = self.learning_const.repeat(int(batches),1,1,1)\n",
        "        for i in range(stage):\n",
        "            if i != 0:\n",
        "                if web:\n",
        "                    x = alternative_Upsample(x,(1,-1,2 ** (i + 1),2 ** (i + 1)))\n",
        "                else:\n",
        "                    x = torch.nn.functional.interpolate(x,scale_factor=2, mode='nearest')\n",
        "            for j in range(2):\n",
        "                if not (i == 0 and j == 0):\n",
        "                    affined_style = getattr(self, 'affine_{0}_{1}'.format(2 ** (i + 2),j))(style)\n",
        "                    if web:\n",
        "                        affined_style_2 = getattr(self, 'affine_{0}_{1}'.format(2 ** (i + 2),j))(style_2)\n",
        "                    if web:\n",
        "                        x = getattr(self, 'block_{0}_{1}'.format(2 ** (i + 2),j))(x,affined_style,shape = (1,-1,2 ** (i + 2),2 ** (i + 2)),style_2 = affined_style_2,web = True)\n",
        "                    else:\n",
        "                        x = getattr(self, 'block_{0}_{1}'.format(2 ** (i + 2),j))(x,affined_style,shape = (1,-1,2 ** (i + 2),2 ** (i + 2)),web = False)\n",
        "                    x = F.leaky_relu(x,LReLU_alpha)\n",
        "                    #x = x + torch.randn(x.shape, device = device) *  getattr(self, 'noise_{0}_{1}'.format(2 ** (i + 2),j))\n",
        "\n",
        "        x_out = getattr(self, 'to_rgb_{0}'.format(2 ** (stage + 1)))(x)\n",
        "\n",
        "        if alpha != 0:\n",
        "            if web:\n",
        "                x = alternative_Upsample(x,(1,-1,2 ** (stage + 1),2 ** (stage + 1)))\n",
        "            else:\n",
        "                x = torch.nn.functional.interpolate(x,scale_factor=2, mode='nearest')\n",
        "            for j in range(2):\n",
        "                affined_style = getattr(self, 'affine_{0}_{1}'.format(2 ** (stage + 2),j))(style)\n",
        "                x = getattr(self, 'block_{0}_{1}'.format(2 ** (stage + 2),j))(x,affined_style,shape = (1,-1,2 ** (stage + 1),2 ** (stage + 1)))\n",
        "                x = F.leaky_relu(x,LReLU_alpha)\n",
        "                #x = x + torch.randn(x.shape, device = device) * getattr(self, 'noise_{0}_{1}'.format(2 ** (i + 2),j))\n",
        "            x = getattr(self, 'to_rgb_{0}'.format(2 ** (stage + 2)))(x)\n",
        "            if web:\n",
        "                x_out = alpha * x + alternative_Upsample(x_out,(1,-1,2 ** (stage + 1),2 ** (stage + 1))) * (1 - alpha)\n",
        "            else:\n",
        "                x_out = alpha * x + torch.nn.functional.interpolate(x,scale_factor=2, mode='nearest') * (1 - alpha)\n",
        "            \n",
        "        return x_out"
      ],
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl4fVrUadKk4"
      },
      "source": [
        "# Define model\n",
        "from torch.autograd import Variable\n",
        "from torch import autograd\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        dimensions = [256,256,256,128,128,128,64,64,64,32,32,32]\n",
        "\n",
        "        self.from_rgb_4 = nn.Conv2d(3,dimensions[2],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_4_0 = self.generate_block(4,dimensions[2],dimensions[1])\n",
        "        self.block_4_1 = self.generate_block(4,dimensions[1],dimensions[0])\n",
        "\n",
        "        self.from_rgb_8 = nn.Conv2d(3,dimensions[4],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_8_0 = self.generate_block(8,dimensions[4],dimensions[3])\n",
        "        self.block_8_1 = self.generate_block(8,dimensions[3],dimensions[2])\n",
        "\n",
        "        self.from_rgb_16 = nn.Conv2d(3,dimensions[6],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_16_0 = self.generate_block(16,dimensions[6],dimensions[5])\n",
        "        self.block_16_1 = self.generate_block(16,dimensions[5],dimensions[4])\n",
        "\n",
        "        self.from_rgb_32 = nn.Conv2d(3,dimensions[8],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_32_0 = self.generate_block(32,dimensions[8],dimensions[7])\n",
        "        self.block_32_1 = self.generate_block(32,dimensions[7],dimensions[6])\n",
        "\n",
        "        self.from_rgb_64 = nn.Conv2d(3,dimensions[10],kernel_size=1,stride=1,padding=0)\n",
        "        self.block_64_0 = self.generate_block(64,dimensions[10],dimensions[9])\n",
        "        self.block_64_1 = self.generate_block(64,dimensions[9],dimensions[8])\n",
        "\n",
        "        self.final_conv = nn.Conv2d(dimensions[0],dimensions[0],kernel_size=4,stride=1,padding=0)\n",
        "        self.linear = nn.Linear(dimensions[0],1)\n",
        "        print(self.final_conv.weight)\n",
        "        nn.init.normal_(self.final_conv.weight, 0.0, 1.0 / (4*4**dimensions[0]) ** 0.5)\n",
        "        nn.init.constant_(self.final_conv.bias, 0)\n",
        "        nn.init.normal_(self.linear.weight, 0.0, 1.0)\n",
        "        nn.init.constant_(self.linear.bias, 0)\n",
        "        for i in range(5):\n",
        "            nn.init.normal_(getattr(self, 'from_rgb_{0}'.format(2 ** (i + 2))).weight, 0.0, 1.0 / getattr(self, 'from_rgb_{0}'.format(2 ** (i + 2))).weight.shape[1] ** 0.5)\n",
        "            nn.init.constant_(getattr(self, 'from_rgb_{0}'.format(2 ** (i + 2))).bias, 0.0)\n",
        "\n",
        "    def generate_block(self,image_size = 4,in_dimension = 512, out_dimension = 512):\n",
        "        block = nn.Sequential()\n",
        "\n",
        "        block.add_module('Conv', nn.Conv2d(in_dimension,out_dimension,kernel_size=3,stride=1,padding=1))\n",
        "        block.add_module('relu', nn.LeakyReLU(LReLU_alpha))\n",
        "        nn.init.normal_(block.Conv.weight, 0.0, 1.0)\n",
        "        nn.init.constant_(block.Conv.bias, 0)\n",
        "\n",
        "        return block\n",
        "    #https://github.com/Zeleni9/pytorch-wgan/blob/master/models/wgan_gradient_penalty.py を改変\n",
        "    def calculate_gradient_penalty(self, real_images, fake_images,batch_size,stage,alpha):\n",
        "        eta = torch.FloatTensor(batch_size,1,1,1).uniform_(0,1).to(device)\n",
        "        eta = eta.expand(batch_size, real_images.size(1), real_images.size(2), real_images.size(3))\n",
        "\n",
        "        interpolated = eta * real_images + ((1 - eta) * fake_images)\n",
        "\n",
        "        # define it to calculate gradient\n",
        "        interpolated = Variable(interpolated, requires_grad=True)\n",
        "        # calculate probability of interpolated examples\n",
        "        prob_interpolated = self(interpolated,stage,alpha)\n",
        "        # calculate gradients of probabilities with respect to examples\n",
        "        gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                              grad_outputs=torch.ones(\n",
        "                                  prob_interpolated.size()).to(device),\n",
        "                              create_graph=True, retain_graph=True)[0]\n",
        "        grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "        return grad_penalty\n",
        "    \n",
        "    def forward(self, image, stage = 1 ,alpha = 0, batches = 1):\n",
        "        if alpha != 0:\n",
        "            x = getattr(self, 'from_rgb_{0}'.format(2 ** (stage + 2)))(image)\n",
        "            for j in range(2):\n",
        "                x = getattr(self, 'block_{0}_{1}'.format(2 ** (stage + 2),j))(x)\n",
        "            x = torch.nn.functional.interpolate(x,scale_factor=0.5, mode='nearest')\n",
        "            x2 = getattr(self, 'from_rgb_{0}'.format(2 ** (stage + 1)))(torch.nn.functional.interpolate(image,scale_factor=0.5, mode='nearest'))\n",
        "            x = x * alpha + x2 * (1 - alpha)\n",
        "        else:\n",
        "            x = getattr(self, 'from_rgb_{0}'.format(2 ** (stage + 1)))(image)\n",
        "\n",
        "        for i in range(stage):\n",
        "            for j in range(2):\n",
        "                if not (i == stage - 1 and j == 1):\n",
        "                    x = getattr(self, 'block_{0}_{1}'.format(2 ** (stage + 1 - i),j))(x)\n",
        "            if i != stage - 1:\n",
        "                x = torch.nn.functional.interpolate(x,scale_factor=0.5, mode='nearest')\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "        \n",
        "        x = nn.LeakyReLU(LReLU_alpha)(x)\n",
        "        x = nn.Flatten()(x)\n",
        "        return  self.linear(x)"
      ],
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evars0QQOPuM"
      },
      "source": [
        "class trainer():\n",
        "    def __init__(self,learning_rate = 0.0002):\n",
        "        self.alpha = 0\n",
        "        self.stage = 0\n",
        "        self.MAX_STAGE = 4\n",
        "        self.BATCH_SIZE = 32\n",
        "        self.n_critic = 1\n",
        "        self.gp_lamda = 1\n",
        "        self.g = Generator().to(device)\n",
        "        self.d = Discriminator().to(device)\n",
        "        self.G_optimizer = torch.optim.Adam(self.g.parameters(), lr=learning_rate)\n",
        "        self.D_optimizer = torch.optim.Adam(self.d.parameters(), lr=learning_rate)\n",
        "        self.NUM_EPOCH_NO_ALPHA = 50\n",
        "        self.NUM_EPOCH_WITH_ALPHA = 50\n",
        "        self.z_dimension = 256\n",
        "    def train(self):\n",
        "        MAX_STAGE = self.MAX_STAGE\n",
        "        BATCH_SIZE = self.BATCH_SIZE\n",
        "        n_critic = self.n_critic\n",
        "        gp_lamda = self.gp_lamda\n",
        "        g = self.g\n",
        "        d = self.d\n",
        "        G_optimizer = self.G_optimizer\n",
        "        D_optimizer = self.D_optimizer\n",
        "        NUM_EPOCH_NO_ALPHA = self.NUM_EPOCH_NO_ALPHA\n",
        "        NUM_EPOCH_WITH_ALPHA = self.NUM_EPOCH_WITH_ALPHA\n",
        "        z_dimension = self.z_dimension\n",
        "        training_data = datasets.CIFAR10(\n",
        "            root=\"data\",\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=ToTensor(),\n",
        "        )\n",
        "        train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "        while True:\n",
        "            for epoch in range(NUM_EPOCH_NO_ALPHA + NUM_EPOCH_WITH_ALPHA):\n",
        "                number_of_batch = 0\n",
        "                for X, _ in train_dataloader:\n",
        "                    X = X * 2 - 1\n",
        "                    \n",
        "                    alpha = 0\n",
        "                    if int(self.stage) % 2 == 1:\n",
        "                        self.stage += 1 / (len(train_dataloader) * NUM_EPOCH_WITH_ALPHA) \n",
        "                    elif math.ceil(self.stage / 2) < self.MAX_STAGE:\n",
        "                        self.stage += 1 / (len(train_dataloader) * NUM_EPOCH_NO_ALPHA)\n",
        "                    stage = math.ceil(self.stage / 2)    \n",
        "                    if int(self.stage) % 2 == 1:\n",
        "                        alpha = self.stage - int(self.stage)\n",
        "                    \n",
        "                    for _ in range(n_critic):\n",
        "                        z = torch.randn((BATCH_SIZE,z_dimension),device = device)\n",
        "                        generated = g(z, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        X = X.to(device)\n",
        "                        X = torch.nn.functional.interpolate(X,size=generated.size(2), mode='Nearest')\n",
        "                        y_real = d(X, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        y_fake = d(generated, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        d_loss = torch.mean(y_fake) - torch.mean(y_real) + d.calculate_gradient_penalty(X,generated,BATCH_SIZE,stage,alpha) * gp_lamda\n",
        "                        Wasserstein_loss =  (torch.mean(y_fake) - torch.mean(y_real)).data\n",
        "\n",
        "                        D_optimizer.zero_grad()\n",
        "                        d_loss.backward()\n",
        "                        D_optimizer.step()\n",
        "                    g_loss = 'undefined'\n",
        "                    if Wasserstein_loss <= 0:\n",
        "                        z = torch.randn((BATCH_SIZE,z_dimension),device = device)\n",
        "                        generated = g(z, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        y_fake = d(generated, stage = stage ,alpha = alpha, batches = BATCH_SIZE)\n",
        "                        g_loss = -torch.mean(y_fake)\n",
        "                        G_optimizer.zero_grad()\n",
        "                        g_loss.backward()\n",
        "                        G_optimizer.step()\n",
        "\n",
        "                    \n",
        "\n",
        "                    if number_of_batch % 100 == 0:\n",
        "                        print('epoch:{}, batch:{},stage:{},alpha{},g_loss:{}, d_loss:{}, Wasserstein Loss:{}'.format(epoch,number_of_batch,stage,alpha,g_loss,d_loss,Wasserstein_loss))\n",
        "                        show_image(generated)\n",
        "                        show_image(X)\n",
        "                        torch.save(self, '/content/drive/MyDrive/StyleGAN2/model.pth')\n",
        "                    number_of_batch += 1"
      ],
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMy29H2BzU5w",
        "outputId": "49fb62a8-20fa-4fec-a529-eeb4d87859a9"
      },
      "source": [
        "try:\n",
        "    train = torch.load('/content/drive/MyDrive/StyleGAN2/model.pth')\n",
        "except:\n",
        "    train = trainer()\n",
        "    print('load failed')\n",
        "\n",
        "dummy_input = torch.randn(1, train.z_dimension, device=device)\n",
        "train.g.learning_const.requires_grad = False\n",
        "for i in range(5):  \n",
        "    for j in range(2):\n",
        "        getattr(train.g, 'noise_{0}_{1}'.format(2 ** (i + 2),j)).requires_grad = False\n",
        "        getattr(train.g, 'noise_{0}_{1}'.format(2 ** (i + 2),j)).requires_grad = False\n",
        "stage = torch.tensor(2, dtype=torch.int)\n",
        "alpha = torch.tensor(0, dtype=torch.int)\n",
        "batches = torch.tensor(1, dtype=torch.int)\n",
        "web = torch.tensor(True, dtype=torch.bool)\n",
        "torch.onnx.export(train.g, (dummy_input,stage,alpha,batches,web), 'generator.onnx', opset_version= 9)"
      ],
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:129: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:133: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:143: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:145: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:136: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBqbMLLl5Ip8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5ef627ff-67a5-47c0-a0a3-f20c42d82b97"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('generator.onnx')"
      ],
      "execution_count": 578,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_61132d1e-3b58-4359-9e1f-9fcfbca2f78c\", \"generator.onnx\", 11050486)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMqPXkseJ6xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace8e239-29b6-4b75-e807-79112e63fea3"
      },
      "source": [
        "#train = torch.load('/content/drive/MyDrive/StyleGAN2/model.pth')\n",
        "train = trainer()\n",
        "z = torch.zeros(1, train.z_dimension, device=device)\n",
        "train.g(z,web=True)"
      ],
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 4.1063e-04,  1.2369e-02,  6.2745e-03, -1.0765e-02],\n",
            "          [-2.7792e-03, -1.3027e-02, -7.6648e-04, -1.2463e-02],\n",
            "          [-7.0482e-03,  1.8424e-03, -1.2469e-02, -1.4241e-02],\n",
            "          [ 1.2266e-02, -1.3108e-02,  1.0462e-03, -9.5371e-03]],\n",
            "\n",
            "         [[-1.2973e-02,  9.4841e-03, -1.0359e-02,  7.0104e-03],\n",
            "          [ 3.7099e-03, -8.1292e-03,  1.1262e-02, -7.1325e-03],\n",
            "          [ 1.1717e-02,  1.1271e-02,  1.2432e-02,  1.4284e-02],\n",
            "          [ 1.1957e-03, -5.3757e-04, -1.0045e-02, -5.1959e-03]],\n",
            "\n",
            "         [[ 1.4351e-02, -2.3700e-03,  5.5031e-03, -7.4885e-03],\n",
            "          [ 9.9936e-04, -4.5484e-03,  7.7253e-04, -1.2931e-02],\n",
            "          [ 1.4001e-02, -7.2244e-03, -6.7728e-03, -1.3145e-02],\n",
            "          [ 3.3331e-03,  3.2093e-03,  8.8484e-03,  3.2466e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4181e-03,  1.4955e-02, -5.1061e-03,  1.0246e-02],\n",
            "          [ 3.8197e-03,  3.2903e-03, -1.3589e-02, -4.7505e-03],\n",
            "          [ 1.6433e-03, -1.2454e-02, -1.5099e-02,  9.1703e-03],\n",
            "          [ 1.2877e-02,  3.9069e-03,  8.6556e-03, -1.4970e-02]],\n",
            "\n",
            "         [[ 9.7585e-03, -1.0751e-02, -3.4929e-04, -3.2374e-03],\n",
            "          [-1.0980e-02,  3.2100e-03, -1.5203e-02, -1.5280e-02],\n",
            "          [ 1.1816e-02, -1.1711e-02,  1.3574e-02, -5.0917e-03],\n",
            "          [-4.7580e-04,  6.7623e-03, -9.4120e-03,  1.5528e-02]],\n",
            "\n",
            "         [[-3.1138e-03,  2.1143e-03, -4.1009e-03,  8.7262e-03],\n",
            "          [-4.9471e-03, -1.3476e-02,  1.0454e-02, -5.7826e-03],\n",
            "          [-6.1502e-03, -1.3526e-02, -1.5325e-02,  8.8901e-03],\n",
            "          [ 8.0524e-03,  6.0343e-04, -4.3290e-03,  3.4814e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4279e-03,  1.1027e-03,  9.7271e-03, -1.4783e-02],\n",
            "          [-1.5156e-02, -1.1110e-02, -1.2809e-02, -2.2729e-03],\n",
            "          [-3.1425e-03,  6.9412e-04, -1.4956e-02,  6.6607e-03],\n",
            "          [-7.6647e-03,  2.8015e-03,  8.5553e-03,  1.4040e-02]],\n",
            "\n",
            "         [[ 1.0854e-02,  1.4799e-02,  1.3732e-02, -1.1170e-02],\n",
            "          [ 7.0781e-03, -1.0011e-02, -3.1521e-03,  7.1401e-03],\n",
            "          [ 4.3541e-03, -9.1683e-03,  1.3395e-03,  4.2745e-03],\n",
            "          [-4.2850e-03, -7.8015e-03, -1.4105e-02,  6.1894e-05]],\n",
            "\n",
            "         [[ 8.0806e-03,  1.1870e-02, -2.0888e-04, -1.5205e-02],\n",
            "          [-1.1477e-02, -1.1545e-02,  1.1275e-02, -1.5426e-02],\n",
            "          [-2.0338e-03, -4.5934e-03,  5.7794e-03, -5.0017e-03],\n",
            "          [-8.2829e-03,  4.5968e-03, -5.8646e-03, -9.9288e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.8892e-03,  9.0811e-03,  5.0130e-03, -2.1518e-04],\n",
            "          [-2.0834e-04, -1.1598e-02,  7.0929e-03, -1.0913e-02],\n",
            "          [-6.2050e-03, -3.7137e-03,  9.4694e-03, -1.9591e-03],\n",
            "          [ 9.1372e-03,  1.4678e-02, -1.1434e-02,  9.3648e-03]],\n",
            "\n",
            "         [[ 2.0873e-03,  1.4183e-02,  1.3874e-02,  9.4076e-03],\n",
            "          [ 8.5514e-03,  7.2803e-03,  1.4043e-02,  7.9379e-03],\n",
            "          [-1.5698e-03, -2.3422e-03, -3.3715e-03, -1.5079e-02],\n",
            "          [ 1.1250e-02,  1.1524e-02,  9.4704e-03,  6.1597e-03]],\n",
            "\n",
            "         [[-1.2756e-02,  3.3648e-03, -2.3915e-03,  2.3768e-04],\n",
            "          [-1.2316e-03,  8.6864e-03, -2.3864e-03,  8.5862e-03],\n",
            "          [-2.4610e-03, -1.2134e-02,  4.7909e-03, -1.3414e-02],\n",
            "          [-1.4426e-02,  6.3533e-03,  2.4418e-03,  7.2127e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.2843e-03,  1.2999e-02, -7.6883e-03, -1.1930e-02],\n",
            "          [ 2.0656e-03, -1.4238e-02,  5.1590e-03,  4.4182e-03],\n",
            "          [-1.4631e-02, -5.5974e-03, -1.0765e-02, -5.7915e-03],\n",
            "          [ 1.0618e-02,  9.2188e-03,  1.6536e-03,  1.2590e-02]],\n",
            "\n",
            "         [[ 5.3887e-03,  1.3959e-02,  1.4730e-02, -4.9130e-03],\n",
            "          [-3.9278e-03,  1.1942e-02, -1.1706e-02, -9.0239e-03],\n",
            "          [ 5.9656e-03, -1.4717e-03, -1.2689e-02, -1.2370e-02],\n",
            "          [ 7.2447e-03, -1.2540e-02, -2.9826e-04, -1.2940e-02]],\n",
            "\n",
            "         [[-1.3640e-02, -1.4494e-02, -5.9032e-03,  1.2236e-02],\n",
            "          [ 9.6233e-03, -6.7618e-03, -9.0579e-03, -1.4257e-02],\n",
            "          [-9.3244e-03,  1.3307e-02,  7.7674e-04, -3.1135e-03],\n",
            "          [-5.2043e-03,  5.4135e-03, -9.8613e-03, -5.7875e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1019e-02,  2.5130e-03,  2.8458e-04,  6.2677e-03],\n",
            "          [ 3.9041e-03, -1.4899e-02, -6.6708e-03, -1.5413e-02],\n",
            "          [-1.2655e-02,  1.5537e-02, -5.9804e-03, -1.0455e-02],\n",
            "          [-4.8934e-03, -8.0605e-03, -1.1919e-02,  2.4517e-03]],\n",
            "\n",
            "         [[-1.2822e-02, -5.6220e-03,  5.3148e-03, -1.2925e-02],\n",
            "          [ 1.2963e-02, -1.3843e-02, -4.0876e-03,  2.0696e-03],\n",
            "          [ 6.4842e-03, -4.0148e-03, -1.2428e-02, -6.2600e-03],\n",
            "          [-1.0918e-02,  4.2893e-03, -6.3596e-03, -3.1051e-03]],\n",
            "\n",
            "         [[ 1.2648e-03,  5.5152e-03, -5.3834e-04,  8.3740e-03],\n",
            "          [-1.1130e-02, -7.7428e-03,  5.8369e-03, -5.0449e-03],\n",
            "          [-1.3762e-03,  3.3912e-03,  1.1859e-02, -1.4675e-02],\n",
            "          [ 1.4392e-02,  9.6154e-03,  8.8763e-03,  3.9842e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0965e-02,  8.2600e-03,  1.7791e-03, -1.2402e-02],\n",
            "          [ 1.0361e-02,  1.5045e-03,  9.5087e-04, -4.1955e-03],\n",
            "          [ 5.0554e-03,  1.1265e-03, -1.3041e-02,  1.5428e-02],\n",
            "          [ 4.5727e-03, -4.5148e-03,  9.8858e-03,  6.1923e-03]],\n",
            "\n",
            "         [[ 6.8979e-03, -7.4104e-03,  6.3026e-03,  1.3465e-02],\n",
            "          [-1.0013e-02, -1.1536e-02, -5.5774e-03,  3.6117e-03],\n",
            "          [ 7.5232e-03, -6.4464e-03,  1.1797e-02, -3.5056e-03],\n",
            "          [-1.5478e-02,  4.5262e-03, -1.2838e-02, -8.0601e-03]],\n",
            "\n",
            "         [[ 8.6705e-03, -1.7019e-03,  9.4647e-03,  6.5942e-03],\n",
            "          [-6.8114e-03, -9.7486e-03, -1.3736e-02,  6.2374e-03],\n",
            "          [-7.9692e-03, -1.4979e-02, -1.0157e-02, -1.4085e-02],\n",
            "          [-9.9371e-03,  1.0788e-02, -1.4418e-02, -2.5435e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.6056e-04,  5.9073e-03, -5.1056e-03,  1.3485e-02],\n",
            "          [ 1.3416e-02, -1.4083e-02, -3.9456e-03,  2.8787e-03],\n",
            "          [-3.6335e-03,  1.0530e-02,  8.9549e-03,  8.3181e-03],\n",
            "          [-6.0744e-03, -1.0316e-02, -1.4473e-03, -1.3279e-02]],\n",
            "\n",
            "         [[ 6.1880e-04,  1.2842e-02, -1.0954e-02, -1.2973e-02],\n",
            "          [ 6.2834e-03,  1.4881e-02, -8.7398e-03, -1.2165e-02],\n",
            "          [ 3.6749e-03, -3.8998e-03,  4.6341e-03,  8.6483e-03],\n",
            "          [-1.0143e-02, -1.1660e-02, -9.7263e-03,  1.4405e-02]],\n",
            "\n",
            "         [[-1.3494e-02, -1.1196e-03,  1.3277e-02,  7.2742e-03],\n",
            "          [ 6.3613e-03, -7.5455e-03, -2.5840e-03,  1.2429e-02],\n",
            "          [ 7.7212e-03,  8.7387e-03,  3.4642e-03, -9.7153e-03],\n",
            "          [-4.0264e-03,  6.1839e-04,  1.5326e-02, -8.1041e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.8086e-03, -1.5558e-02,  2.9223e-03,  1.2805e-02],\n",
            "          [-1.3372e-02,  1.0739e-02,  1.5175e-02, -2.6337e-03],\n",
            "          [ 1.1801e-02, -1.1836e-02, -5.5705e-03, -1.4015e-02],\n",
            "          [ 8.4519e-03, -6.2915e-03, -1.3162e-02, -4.9193e-03]],\n",
            "\n",
            "         [[ 7.1941e-03,  8.4130e-03,  6.8908e-03, -6.9408e-03],\n",
            "          [-1.1107e-02, -1.3821e-02,  1.3132e-02,  1.1305e-03],\n",
            "          [-1.1811e-02,  1.1272e-02,  5.2323e-03, -2.6128e-03],\n",
            "          [-1.6284e-03,  3.4859e-03,  1.1883e-02,  1.2205e-02]],\n",
            "\n",
            "         [[ 1.1608e-02, -7.6704e-03, -9.6741e-03,  7.6373e-03],\n",
            "          [ 3.9221e-03,  9.8572e-03,  9.0799e-03,  1.3516e-02],\n",
            "          [ 1.4139e-02, -7.9449e-05,  4.4492e-03, -6.7544e-03],\n",
            "          [ 4.5967e-03,  7.7147e-03, -1.5414e-02, -8.0407e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0032e-02,  5.3485e-03,  5.5417e-03,  1.0939e-02],\n",
            "          [ 1.4002e-02,  4.5132e-03,  5.5530e-03, -1.5255e-02],\n",
            "          [-1.5377e-02, -9.2497e-03,  1.9605e-03, -9.9187e-03],\n",
            "          [-2.6664e-03,  8.1786e-03,  1.4602e-02,  8.3085e-03]],\n",
            "\n",
            "         [[ 1.0856e-02, -2.9474e-03, -3.3862e-03,  1.2343e-02],\n",
            "          [-9.3582e-03,  1.1933e-02,  4.0667e-03, -2.7878e-03],\n",
            "          [-9.4441e-03,  1.2777e-02,  1.8826e-03, -5.9243e-03],\n",
            "          [-4.6258e-03, -4.9269e-03, -8.6260e-03,  2.3197e-03]],\n",
            "\n",
            "         [[ 1.9603e-03, -1.4703e-02, -1.2685e-03,  3.9786e-03],\n",
            "          [ 1.5562e-02,  1.3028e-02,  2.0866e-03, -7.1486e-03],\n",
            "          [ 9.8267e-03, -1.3816e-02, -1.4609e-02,  1.2655e-02],\n",
            "          [-7.5365e-03, -1.0161e-02,  9.7749e-03,  8.6449e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.0389e-03, -6.1199e-03, -1.8258e-03,  1.5363e-02],\n",
            "          [-5.6239e-03,  5.9643e-04, -8.9207e-03, -6.0024e-04],\n",
            "          [ 1.0554e-02, -1.4647e-02,  2.3736e-03, -1.0690e-02],\n",
            "          [-5.6027e-03,  1.4007e-02, -1.4016e-02, -2.0269e-03]],\n",
            "\n",
            "         [[ 3.3285e-03, -1.4222e-02, -8.5841e-03,  1.0980e-02],\n",
            "          [-1.1067e-03, -1.0764e-02,  1.4205e-02,  1.1248e-02],\n",
            "          [-1.2558e-02,  1.1927e-02,  3.2271e-03,  2.8541e-03],\n",
            "          [-7.7828e-03,  9.9874e-03,  1.2405e-02,  4.2709e-03]],\n",
            "\n",
            "         [[ 1.1408e-02,  4.9178e-03,  8.1021e-03, -1.0489e-02],\n",
            "          [-1.0623e-02, -5.0471e-03, -7.0385e-03, -4.9701e-03],\n",
            "          [-1.5353e-02, -1.7185e-03, -4.5726e-03,  1.9137e-03],\n",
            "          [-7.2135e-03, -5.5974e-03,  4.8733e-03, -3.1727e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2119e-03, -9.3335e-03, -1.4435e-03, -4.6514e-03],\n",
            "          [ 1.0435e-02, -1.4058e-02, -3.1708e-03, -8.9341e-03],\n",
            "          [-5.5873e-03, -1.1499e-02,  7.0733e-03, -5.8341e-03],\n",
            "          [ 9.5647e-03, -2.7511e-03, -4.7246e-03,  1.2576e-02]],\n",
            "\n",
            "         [[ 1.0627e-02,  2.2558e-03, -1.2724e-02, -9.3078e-03],\n",
            "          [-1.3717e-02,  8.2533e-03, -1.0073e-02,  1.2389e-02],\n",
            "          [ 6.0497e-03, -8.8679e-03,  8.6062e-03, -1.8290e-03],\n",
            "          [ 1.1833e-05,  3.2342e-03,  1.4006e-02, -5.7270e-03]],\n",
            "\n",
            "         [[-1.0441e-02, -1.3116e-02,  6.2045e-03, -8.0532e-03],\n",
            "          [ 5.4340e-03, -1.6786e-03,  7.7855e-03, -4.7518e-03],\n",
            "          [ 6.9268e-03, -5.3472e-03,  5.1347e-03, -6.8580e-03],\n",
            "          [-1.0148e-02,  4.7656e-03, -9.8666e-03,  7.1399e-05]]]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.1413,  0.2075,  0.3919, -0.3964],\n",
              "          [ 0.7401,  0.1210,  0.2165, -0.2177],\n",
              "          [-0.2314,  0.6303,  0.9956, -0.5995],\n",
              "          [ 0.8156,  0.7754,  0.3953, -0.4216]],\n",
              "\n",
              "         [[ 0.5527,  0.8440,  0.4769,  0.4931],\n",
              "          [ 0.2834,  0.5217,  0.5226, -0.0878],\n",
              "          [-0.0370,  0.4777, -0.4944,  0.8379],\n",
              "          [-0.0335,  0.7102,  0.7463,  0.4023]],\n",
              "\n",
              "         [[-0.1886,  0.7285, -0.2532,  0.5262],\n",
              "          [-0.9401,  0.3649,  0.4857,  0.1959],\n",
              "          [-0.1238, -0.8521, -0.1096,  0.2135],\n",
              "          [-0.0262,  0.9493, -0.4568,  0.3329]]]], device='cuda:0',\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 579
        }
      ]
    }
  ]
}